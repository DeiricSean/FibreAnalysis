{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batchSize=2\n",
    "imageSize=[600,600]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')   # train on the GPU or on the CPU, if a GPU is not available\n",
    "trainDir=\"/home/breakeroftime/Documents/Datasets/LabPics/LabPicsChemistry/Train\"\n",
    "\n",
    "imgs=[]\n",
    "\n",
    "# Update in colab\n",
    "imagePath = r\"C:\\Users\\dezos\\Documents\\Fibres\\FibreAnalysis\"\n",
    "\n",
    "sample_images = os.path.join(imagePath, 'Data', 'synth', 'images', '')\n",
    "sample_masks = os.path.join(imagePath, 'Data', 'synth', 'masks', '')\n",
    "\n",
    "\n",
    "imgs=[]\n",
    "# for pth in os.listdir(sample_images):\n",
    "#     imgs.append(pth )\n",
    "\n",
    "# Define the file pattern\n",
    "file_pattern = os.path.join(sample_images, \"*.png\") \n",
    "\n",
    "# Use glob to retrieve all matching file paths\n",
    "file_paths = glob.glob(file_pattern)\n",
    "# Extract filenames without the path\n",
    "imgs = [os.path.basename(file_path) for file_path in file_paths]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "batchSize=2\n",
    "imageSize=[600,600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loadData():\n",
    "  batch_Imgs=[]\n",
    "  batch_Data=[]\n",
    "  for i in range(batchSize):        \n",
    "        idx=random.randint(0,len(imgs)-1)\n",
    "        img = cv2.imread(os.path.join(sample_images , imgs[idx]))\n",
    "        img = cv2.resize(img, imageSize, cv2.INTER_LINEAR)       \n",
    "        \n",
    "        sample_masks = os.path.join(imagePath, 'Data', 'synth', 'masks', '')\n",
    "        masks=[]\n",
    "\n",
    "        filename, extension = os.path.splitext(imgs[idx])\n",
    "        maskFile =  \"mask\" + filename[5:] + extension\n",
    "\n",
    "        vesMask = cv2.imread(os.path.join(sample_masks , maskFile), 0)     \n",
    "\n",
    "\n",
    "        vesMask = (vesMask > 0).astype(np.uint8) \n",
    "        vesMask=cv2.resize(vesMask,imageSize,cv2.INTER_NEAREST)\n",
    "        \n",
    "        masks.append(vesMask)        \n",
    "        num_objs = len(masks)\n",
    "        \n",
    "        if num_objs==0: return loadData()        \n",
    "        boxes = torch.zeros([num_objs,4], dtype=torch.float32)\n",
    "        \n",
    "        for i in range(num_objs):\n",
    "            x,y,w,h = cv2.boundingRect(masks[i])\n",
    "            boxes[i] = torch.tensor([x, y, x+w, y+h])\n",
    "        \n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        \n",
    "        tempImg = img\n",
    "        \n",
    "        img = torch.as_tensor(img, dtype=torch.float32)        \n",
    "        data = {}\n",
    "        data[\"boxes\"] =  boxes\n",
    "        data[\"labels\"] =  torch.ones((num_objs,), dtype=torch.int64)   \n",
    "        data[\"masks\"] = masks        \n",
    "        batch_Imgs.append(img)\n",
    "        batch_Data.append(data)\n",
    "        \n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(tempImg, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # # Display the image\n",
    "        cv2.imshow(\"Image with Bounding Box\", tempImg)\n",
    "\n",
    "        # # Wait for a key press and close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()  \n",
    "  \n",
    "  batch_Imgs=torch.stack([torch.as_tensor(d) for d in batch_Imgs],0)\n",
    "  batch_Imgs = batch_Imgs.swapaxes(1, 3).swapaxes(2, 3)\n",
    "  return batch_Imgs, batch_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)  # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features  # get number of input features for the classifier\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes=2)  # replace the pre-trained head with a new one\n",
    "model.to(device)# move model to the right devic\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "model.train()\n",
    "\n",
    "for i in range(10001):\n",
    "            images, targets = loadData()\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            print(i,'loss:', losses.item())\n",
    "            if i%500==0:\n",
    "                torch.save(model.state_dict(), str(i)+\".torch\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
