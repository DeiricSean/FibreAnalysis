{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#    Author  : Derek O'Sullivan\n",
        "#    Date    : 14/08/23\n",
        "\n",
        "#    Purpose : Cropping of real world images. These don't have any ground truth masks and the YOLO polygons are \n",
        "#              based on identified contours from the images themselves. For more accuracy, an annotation tool \n",
        "#              could be used to create the ground truth masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUh6kzDScbQA",
        "outputId": "f5971c73-5bbb-4428-e7b7-1e504e6f5784"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re   # Regular expressions\n",
        "from sklearn.cluster import KMeans\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dgRPahi5cbQC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def imagePreparation(image, numROI ):\n",
        "\n",
        "    height, width = image.shape[:2]\n",
        "    imageArea = height * width\n",
        "\n",
        "    resized = imutils.resize(image, width=300)\n",
        "\n",
        "    ratio = image.shape[0] / float(resized.shape[0])\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(resized, (5, 5), 0)\n",
        "    \n",
        "    print(blurred)\n",
        "    _, thresh = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Morphological operations to connect and thicken the lines\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    dilated_edges = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # MORPH_CLOSE is useful for closing small gaps\n",
        "    # Canny edge detection\n",
        "    edges = cv2.Canny(dilated_edges, 100, 200)\n",
        "\n",
        "    # Get the contours of the image - to find the grid polygons\n",
        "    contours1, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "    IdentifiedContours = sorted(contours1, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    if len(IdentifiedContours) >= 2:\n",
        "    # Get the areas of the first two contours,this is to identify whether the image has one or two main grid squares\n",
        "        try:\n",
        "            if abs(cv2.contourArea(IdentifiedContours[0]) / cv2.contourArea(IdentifiedContours[1])) < 2 :\n",
        "                numROI = 2\n",
        "            else:\n",
        "                numROI = 1\n",
        "\n",
        "        except:\n",
        "            numROI = 1\n",
        "    # Rescale the image coordinates from the smaller resized image to the actual image\n",
        "    for x in range(numROI):\n",
        "        IdentifiedContours[x][:, 0, 0] = (IdentifiedContours[x][:, 0, 0] * ratio).astype(int)  # Scale the x-coordinates\n",
        "        IdentifiedContours[x][:, 0, 1] = (IdentifiedContours[x][:, 0, 1] * ratio).astype(int)  # Scale the y-coordinates\n",
        "\n",
        "    cropped_images = []  # List to store cropped images\n",
        "    cropped_masks = []   # List to store cropped masks\n",
        "\n",
        "    for i in range(numROI):\n",
        "        if cv2.contourArea(IdentifiedContours[i]) > 0:\n",
        "            # Compute the bounding rectangle for the contour\n",
        "            x, y, w, h = cv2.boundingRect(IdentifiedContours[i])  # Largest contour 0 will be the full\n",
        "                                                                        # image so we ignore that one\n",
        "            cropped_images.append(image[y:y+h, x:x+w])  # Add cropped image to the list\n",
        "\n",
        "    return cropped_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1FFEURRzcbQC"
      },
      "outputs": [],
      "source": [
        "# Convert masks into YOLO suitable labels - based on the masks rather than the images\n",
        "# get_contours and store_polygons are from https://github.com/computervisioneng/image-segmentation-yolov8\n",
        "#\n",
        "def get_contours( inboundMask ):\n",
        "\n",
        "    _, mask = cv2.threshold(inboundMask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    H, W = mask.shape\n",
        "    contours, hierarchy = cv2.findContours(inboundMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # convert the contours to polygons\n",
        "    polygons = []\n",
        "    for cnt in contours:\n",
        "        polygon = []\n",
        "        for point in cnt:\n",
        "            x, y = point[0]\n",
        "            polygon.append(x / W)\n",
        "            polygon.append(y / H)\n",
        "        polygons.append(polygon)\n",
        "\n",
        "    return polygons\n",
        "\n",
        "\n",
        "def store_polygons(directory, file,  inboundPolygons):\n",
        "    # print the polygons\n",
        "    with open('{}.txt'.format(os.path.join(directory, file)[:-4]), 'w') as f:\n",
        "        for polygon in inboundPolygons:\n",
        "            for p_, p in enumerate(polygon):\n",
        "                if p_ == len(polygon) - 1:\n",
        "                    f.write('{}\\n'.format(p))\n",
        "                elif p_ == 0:\n",
        "                    f.write('0 {} '.format(p))\n",
        "                else:\n",
        "                    f.write('{} '.format(p))\n",
        "\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4kc_zbLecbQD"
      },
      "outputs": [],
      "source": [
        "# Main processing\n",
        "def processSynthImages(rawImages, preparedImages):\n",
        "\n",
        "    # Get the list of files to process\n",
        "    tempImageFilenames = os.listdir(rawImages)\n",
        "    imageFilenames = [item for item in tempImageFilenames if os.path.isfile(os.path.join(rawImages, item))]\n",
        "\n",
        "    print(imageFilenames)\n",
        "    for filename in imageFilenames:\n",
        "        # Prepare tarket filenames and locations for mask and image\n",
        "        ImageFile = os.path.join(rawImages, filename)\n",
        "        # read image\n",
        "        img = cv2.imread(ImageFile, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Crop image to show only the grid square/rectangles\n",
        "        croppedImgs = imagePreparation(img, 3)\n",
        "\n",
        "        # Save the resulting images, masks and labels to the target directories\n",
        "        counter = 0\n",
        "        for croppedImg in croppedImgs:\n",
        "            counter += 1\n",
        "\n",
        "            imageName_without_extension, imageExtension = os.path.splitext(filename)\n",
        "            targetImageFile = os.path.join(preparedImages, f\"{imageName_without_extension}_{counter}{imageExtension}\")\n",
        "            cv2.imwrite(targetImageFile, croppedImg)  # Save the image to file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwCM2OnecbQD",
        "outputId": "aedc7295-b675-4cc2-8a1a-74276ac58bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory C:\\Users\\dezos\\OneDrive\\Documents\\FibreAnalysis\\fibreanalysis\n",
            "Processing Images\n",
            "C:\\Users\\dezos\\OneDrive\\Documents\\FibreAnalysis\\fibreanalysis\\Data\\Real\\Raw1\\\n",
            "['2SquareBrown1.png', 'RedBrown3.jpg']\n",
            "[[177 178 179 ... 163 163 163]\n",
            " [176 177 178 ... 162 162 163]\n",
            " [172 173 175 ... 158 159 160]\n",
            " ...\n",
            " [210 210 209 ... 193 192 191]\n",
            " [216 216 216 ... 202 201 200]\n",
            " [218 219 219 ... 207 205 205]]\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n"
          ]
        },
        {
          "ename": "ZeroDivisionError",
          "evalue": "float division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m OutPreparedImages \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(current_directory, \u001b[39m'\u001b[39m\u001b[39mData\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mReal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrepared\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(InRawImages)\n\u001b[1;32m---> 14\u001b[0m processSynthImages(InRawImages, OutPreparedImages)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing Complete\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36mprocessSynthImages\u001b[1;34m(rawImages, preparedImages)\u001b[0m\n\u001b[0;32m     13\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(ImageFile, cv2\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     15\u001b[0m \u001b[39m# Crop image to show only the grid square/rectangles\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m croppedImgs \u001b[39m=\u001b[39m imagePreparation(img, \u001b[39m3\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Save the resulting images, masks and labels to the target directories\u001b[39;00m\n\u001b[0;32m     19\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "Cell \u001b[1;32mIn[3], line 27\u001b[0m, in \u001b[0;36mimagePreparation\u001b[1;34m(image, numROI)\u001b[0m\n\u001b[0;32m     23\u001b[0m IdentifiedContours \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(contours1, key\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mcontourArea, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(IdentifiedContours) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m     26\u001b[0m \u001b[39m# Get the areas of the first two contours,this is to identify whether the image has one or two main grid squares\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(cv2\u001b[39m.\u001b[39;49mcontourArea(IdentifiedContours[\u001b[39m0\u001b[39;49m]) \u001b[39m/\u001b[39;49m cv2\u001b[39m.\u001b[39;49mcontourArea(IdentifiedContours[\u001b[39m1\u001b[39;49m])) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m :\n\u001b[0;32m     28\u001b[0m         numROI \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     29\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ],
      "source": [
        "current_directory = r'C:\\Users\\dezos\\OneDrive\\Documents\\FibreAnalysis\\fibreanalysis'\n",
        "print('Current Directory', current_directory)\n",
        "print('Processing Images')\n",
        "\n",
        "# for stageDirectory in [\"Real\"]:\n",
        "# print(\"Processing Stage: \" , stageDirectory)\n",
        "InRawImages = os.path.join(current_directory, 'Data', 'Real', 'Raw',  '')\n",
        "\n",
        "OutPreparedImages = os.path.join(current_directory, 'Data', 'Real', 'Prepared', '')\n",
        "\n",
        "processSynthImages(InRawImages, OutPreparedImages)\n",
        "\n",
        "print('Processing Complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otNiXnvdDmbm"
      },
      "source": [
        "### Create required directory structure for YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNazvCaWDmbo"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/train\n",
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/val\n",
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/train\n",
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPBPeNBtDmbo"
      },
      "outputs": [],
      "source": [
        "# # Move files across for YOLO\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Train/labels/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/train\n",
        "\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Val/labels/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/val\n",
        "\n",
        "\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Train/images/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/train\n",
        "\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Val/images/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/val"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
