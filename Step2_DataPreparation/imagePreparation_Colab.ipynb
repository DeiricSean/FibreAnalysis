{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUh6kzDScbQA",
        "outputId": "2bfa2c70-3403-4416-f89a-9b1fe01604f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re   # Regular expressions\n",
        "from sklearn.cluster import KMeans\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import imutils\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dgRPahi5cbQC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def imagePreparation(image, mask, numROI ):\n",
        "\n",
        "    height, width = image.shape[:2]\n",
        "    imageArea = height * width\n",
        "\n",
        "    resized = imutils.resize(image, width=300)\n",
        "\n",
        "    ratio = image.shape[0] / float(resized.shape[0])\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(resized, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Morphological operations to connect and thicken the lines\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    dilated_edges = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # MORPH_CLOSE is useful for closing small gaps\n",
        "    # Canny edge detection\n",
        "    edges = cv2.Canny(dilated_edges, 100, 200)\n",
        "\n",
        "    # Get the contours of the image - to find the grid polygons\n",
        "    contours1, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "    IdentifiedContours = sorted(contours1, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    if len(IdentifiedContours) >= 2:\n",
        "    # Get the areas of the first two contours,this is to identify whether the image has one or two main grid squares\n",
        "        if abs(cv2.contourArea(IdentifiedContours[0]) / cv2.contourArea(IdentifiedContours[1])) < 2 :\n",
        "            numROI = 2\n",
        "        else:\n",
        "            numROI = 1\n",
        "\n",
        "    # Rescale the image coordinates from the smaller resized image to the actual image\n",
        "    for x in range(numROI):\n",
        "    #for contour in IdentifiedContours:\n",
        "        IdentifiedContours[x][:, 0, 0] = (IdentifiedContours[x][:, 0, 0] * ratio).astype(int)  # Scale the x-coordinates\n",
        "        IdentifiedContours[x][:, 0, 1] = (IdentifiedContours[x][:, 0, 1] * ratio).astype(int)  # Scale the y-coordinates\n",
        "\n",
        "    cropped_images = []  # List to store cropped images\n",
        "    cropped_masks = []   # List to store cropped masks\n",
        "\n",
        "    for i in range(numROI):\n",
        "        # Compute the bounding rectangle for the contour\n",
        "        x, y, w, h = cv2.boundingRect(IdentifiedContours[i])  # Largest contour 0 will be the full\n",
        "                                                                    # image so we ignore that one\n",
        "        cropped_images.append(image[y:y+h, x:x+w])  # Add cropped image to the list\n",
        "        cropped_masks.append(mask[y:y+h, x:x+w])    # Add cropped mask to the list\n",
        "\n",
        "    return cropped_images, cropped_masks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1FFEURRzcbQC"
      },
      "outputs": [],
      "source": [
        "# Convert masks into YOLO suitable labels - based on the masks rather than the images\n",
        "# get_contours and store_polygons are from https://github.com/computervisioneng/image-segmentation-yolov8\n",
        "#\n",
        "def get_contours( inboundMask ):\n",
        "\n",
        "    _, mask = cv2.threshold(inboundMask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    H, W = mask.shape\n",
        "    contours, hierarchy = cv2.findContours(inboundMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # convert the contours to polygons\n",
        "    polygons = []\n",
        "    for cnt in contours:\n",
        "        polygon = []\n",
        "        for point in cnt:\n",
        "            x, y = point[0]\n",
        "            polygon.append(x / W)\n",
        "            polygon.append(y / H)\n",
        "        polygons.append(polygon)\n",
        "\n",
        "    return polygons\n",
        "\n",
        "\n",
        "def store_polygons(directory, file,  inboundPolygons):\n",
        "    # print the polygons\n",
        "    with open('{}.txt'.format(os.path.join(directory, file)[:-4]), 'w') as f:\n",
        "        for polygon in inboundPolygons:\n",
        "            for p_, p in enumerate(polygon):\n",
        "                if p_ == len(polygon) - 1:\n",
        "                    f.write('{}\\n'.format(p))\n",
        "                elif p_ == 0:\n",
        "                    f.write('0 {} '.format(p))\n",
        "                else:\n",
        "                    f.write('{} '.format(p))\n",
        "\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4kc_zbLecbQD"
      },
      "outputs": [],
      "source": [
        "# Main processing\n",
        "def processSynthImages(rawImages, rawMasks, preparedImages, preparedMasks, preparedLabels):\n",
        "\n",
        "    # Get the list of files to process\n",
        "    tempImageFilenames = os.listdir(rawImages)\n",
        "    imageFilenames = [item for item in tempImageFilenames if os.path.isfile(os.path.join(rawImages, item))]\n",
        "\n",
        "    for filename in imageFilenames:\n",
        "        # Prepare tarket filenames and locations for mask and image\n",
        "        ImageFile = os.path.join(rawImages, filename)\n",
        "        maskFilename = filename.replace('image', 'mask')\n",
        "        labelFilename = filename.replace('image', 'label')\n",
        "\n",
        "        MaskFile = os.path.join(rawMasks, maskFilename)\n",
        "\n",
        "        # read image\n",
        "        img = cv2.imread(ImageFile, cv2.IMREAD_UNCHANGED)\n",
        "        mask = cv2.imread(MaskFile, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Crop image to show only the grid square/rectangles\n",
        "        croppedImgs, croppedMasks = imagePreparation(img, mask, 3)\n",
        "\n",
        "        # Save the resulting images, masks and labels to the target directories\n",
        "        counter = 0\n",
        "        for croppedImg, croppedMask in zip(croppedImgs, croppedMasks):\n",
        "            counter += 1\n",
        "\n",
        "            imageName_without_extension, imageExtension = os.path.splitext(filename)\n",
        "            maskname_without_extension, maskExtension = os.path.splitext(maskFilename)\n",
        "            labelname_without_extension, _ = os.path.splitext(labelFilename)\n",
        "\n",
        "            targetImageFile = os.path.join(preparedImages, f\"{imageName_without_extension}_{counter}{imageExtension}\")\n",
        "            targetMaskFile = os.path.join(preparedMasks, f\"{maskname_without_extension}_{counter}{maskExtension}\")\n",
        "\n",
        "            cv2.imwrite(targetImageFile, croppedImg)  # Save the image to file\n",
        "            cv2.imwrite(targetMaskFile, croppedMask)  # Save the mask to file\n",
        "            store_polygons(preparedLabels, f\"{labelname_without_extension}_{counter}.txt\",  get_contours(croppedMask))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwCM2OnecbQD",
        "outputId": "aedc7295-b675-4cc2-8a1a-74276ac58bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory /content/drive/MyDrive/Colab Notebooks/FibreAnalysis\n",
            "Processing Images\n",
            "Processing Complete\n"
          ]
        }
      ],
      "source": [
        "#current_directory = os.getcwd()\n",
        "current_directory = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis'\n",
        "print('Current Directory', current_directory)\n",
        "print('Processing Images')\n",
        "\n",
        "for stageDirectory in [\"Train\", \"Val\", \"Test\"]:\n",
        "    print(\"Processing Stage: \" , stageDirectory)\n",
        "    InRawImages = os.path.join(current_directory, 'Data', 'synth',stageDirectory, 'images', '')\n",
        "    InRawMasks = os.path.join(current_directory, 'Data', 'synth', stageDirectory,'masks', '')\n",
        "\n",
        "    OutPreparedImages = os.path.join(current_directory, 'Data', 'Prepared', stageDirectory, 'images', '')\n",
        "    OutPreparedMasks = os.path.join(current_directory, 'Data', 'Prepared', stageDirectory, 'masks', '')\n",
        "    OutPreparedLabels = os.path.join(current_directory, 'Data', 'Prepared', stageDirectory, 'labels', '')\n",
        "\n",
        "    processSynthImages(InRawImages, InRawMasks, OutPreparedImages, OutPreparedMasks, OutPreparedLabels)\n",
        "\n",
        "print('Processing Complete')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}