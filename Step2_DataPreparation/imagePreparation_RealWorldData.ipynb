{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUh6kzDScbQA",
        "outputId": "f5971c73-5bbb-4428-e7b7-1e504e6f5784"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re   # Regular expressions\n",
        "from sklearn.cluster import KMeans\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import imutils\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dgRPahi5cbQC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def imagePreparation(image, numROI ):\n",
        "\n",
        "    height, width = image.shape[:2]\n",
        "    imageArea = height * width\n",
        "\n",
        "    resized = imutils.resize(image, width=300)\n",
        "\n",
        "    ratio = image.shape[0] / float(resized.shape[0])\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(resized, (5, 5), 0)\n",
        "    \n",
        "    print(blurred)\n",
        "    _, thresh = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Morphological operations to connect and thicken the lines\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    dilated_edges = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # MORPH_CLOSE is useful for closing small gaps\n",
        "    # Canny edge detection\n",
        "    edges = cv2.Canny(dilated_edges, 100, 200)\n",
        "\n",
        "    # Get the contours of the image - to find the grid polygons\n",
        "    contours1, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "    IdentifiedContours = sorted(contours1, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "    if len(IdentifiedContours) >= 2:\n",
        "    # Get the areas of the first two contours,this is to identify whether the image has one or two main grid squares\n",
        "        if abs(cv2.contourArea(IdentifiedContours[0]) / cv2.contourArea(IdentifiedContours[1])) < 2 :\n",
        "            numROI = 2\n",
        "        else:\n",
        "            numROI = 1\n",
        "\n",
        "    # Rescale the image coordinates from the smaller resized image to the actual image\n",
        "    for x in range(numROI):\n",
        "    #for contour in IdentifiedContours:\n",
        "        IdentifiedContours[x][:, 0, 0] = (IdentifiedContours[x][:, 0, 0] * ratio).astype(int)  # Scale the x-coordinates\n",
        "        IdentifiedContours[x][:, 0, 1] = (IdentifiedContours[x][:, 0, 1] * ratio).astype(int)  # Scale the y-coordinates\n",
        "\n",
        "    cropped_images = []  # List to store cropped images\n",
        "    cropped_masks = []   # List to store cropped masks\n",
        "\n",
        "    for i in range(numROI):\n",
        "        if cv2.contourArea(IdentifiedContours[i]) > 0:\n",
        "            # Compute the bounding rectangle for the contour\n",
        "            x, y, w, h = cv2.boundingRect(IdentifiedContours[i])  # Largest contour 0 will be the full\n",
        "                                                                        # image so we ignore that one\n",
        "            cropped_images.append(image[y:y+h, x:x+w])  # Add cropped image to the list\n",
        "\n",
        "    return cropped_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1FFEURRzcbQC"
      },
      "outputs": [],
      "source": [
        "# Convert masks into YOLO suitable labels - based on the masks rather than the images\n",
        "# get_contours and store_polygons are from https://github.com/computervisioneng/image-segmentation-yolov8\n",
        "#\n",
        "def get_contours( inboundMask ):\n",
        "\n",
        "    _, mask = cv2.threshold(inboundMask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    H, W = mask.shape\n",
        "    contours, hierarchy = cv2.findContours(inboundMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # convert the contours to polygons\n",
        "    polygons = []\n",
        "    for cnt in contours:\n",
        "        polygon = []\n",
        "        for point in cnt:\n",
        "            x, y = point[0]\n",
        "            polygon.append(x / W)\n",
        "            polygon.append(y / H)\n",
        "        polygons.append(polygon)\n",
        "\n",
        "    return polygons\n",
        "\n",
        "\n",
        "def store_polygons(directory, file,  inboundPolygons):\n",
        "    # print the polygons\n",
        "    with open('{}.txt'.format(os.path.join(directory, file)[:-4]), 'w') as f:\n",
        "        for polygon in inboundPolygons:\n",
        "            for p_, p in enumerate(polygon):\n",
        "                if p_ == len(polygon) - 1:\n",
        "                    f.write('{}\\n'.format(p))\n",
        "                elif p_ == 0:\n",
        "                    f.write('0 {} '.format(p))\n",
        "                else:\n",
        "                    f.write('{} '.format(p))\n",
        "\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4kc_zbLecbQD"
      },
      "outputs": [],
      "source": [
        "# Main processing\n",
        "def processSynthImages(rawImages, preparedImages):\n",
        "\n",
        "    # Get the list of files to process\n",
        "    tempImageFilenames = os.listdir(rawImages)\n",
        "    imageFilenames = [item for item in tempImageFilenames if os.path.isfile(os.path.join(rawImages, item))]\n",
        "\n",
        "    for filename in imageFilenames:\n",
        "        # Prepare tarket filenames and locations for mask and image\n",
        "        ImageFile = os.path.join(rawImages, filename)\n",
        "        # read image\n",
        "        img = cv2.imread(ImageFile, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Crop image to show only the grid square/rectangles\n",
        "        croppedImgs = imagePreparation(img, 3)\n",
        "\n",
        "        # Save the resulting images, masks and labels to the target directories\n",
        "        counter = 0\n",
        "        for croppedImg in croppedImgs:\n",
        "            counter += 1\n",
        "\n",
        "            imageName_without_extension, imageExtension = os.path.splitext(filename)\n",
        "            targetImageFile = os.path.join(preparedImages, f\"{imageName_without_extension}_{counter}{imageExtension}\")\n",
        "            cv2.imwrite(targetImageFile, croppedImg)  # Save the image to file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwCM2OnecbQD",
        "outputId": "aedc7295-b675-4cc2-8a1a-74276ac58bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Directory C:\\Users\\dezos\\OneDrive\\Documents\\FibreAnalysis\\fibreanalysis\n",
            "Processing Images\n",
            "[[233 234 235 ... 253 253 253]\n",
            " [230 231 232 ... 253 253 253]\n",
            " [227 228 230 ... 252 253 253]\n",
            " ...\n",
            " [236 237 237 ... 254 255 255]\n",
            " [238 238 239 ... 254 254 254]\n",
            " [238 238 239 ... 253 254 254]]\n",
            "[[242 242 243 ... 244 244 245]\n",
            " [242 242 243 ... 244 245 245]\n",
            " [242 242 243 ... 245 245 245]\n",
            " ...\n",
            " [232 232 232 ... 249 250 250]\n",
            " [233 233 234 ... 249 250 250]\n",
            " [233 234 235 ... 250 250 250]]\n",
            "[[210 214 225 ... 246 246 246]\n",
            " [210 214 223 ... 247 247 247]\n",
            " [212 213 218 ... 248 248 248]\n",
            " ...\n",
            " [224 223 222 ... 249 249 249]\n",
            " [229 228 227 ... 250 250 250]\n",
            " [230 229 228 ... 250 251 251]]\n",
            "[[255 255 255 ... 230 230 230]\n",
            " [255 255 255 ... 230 230 230]\n",
            " [255 255 255 ... 231 231 231]\n",
            " ...\n",
            " [241 241 242 ... 134 144 149]\n",
            " [244 245 246 ... 136 145 150]\n",
            " [246 247 248 ... 137 145 150]]\n",
            "[[255 255 255 ... 202 202 202]\n",
            " [255 255 255 ... 204 204 204]\n",
            " [255 255 255 ... 206 209 209]\n",
            " ...\n",
            " [231 231 230 ... 182 179 177]\n",
            " [234 233 231 ... 195 193 191]\n",
            " [235 234 231 ... 200 199 198]]\n",
            "[[255 255 255 ... 213 212 212]\n",
            " [255 255 255 ... 214 213 212]\n",
            " [255 255 255 ... 217 215 214]\n",
            " ...\n",
            " [241 242 244 ... 227 222 219]\n",
            " [241 242 245 ... 228 225 223]\n",
            " [241 242 245 ... 229 227 225]]\n",
            "[[253 253 254 ... 230 231 230]\n",
            " [254 254 254 ... 230 230 230]\n",
            " [254 254 254 ... 230 229 229]\n",
            " ...\n",
            " [255 255 255 ... 213 212 212]\n",
            " [255 255 255 ... 214 213 212]\n",
            " [255 255 255 ... 215 213 212]]\n",
            "[[229 229 230 ... 233 229 226]\n",
            " [229 229 230 ... 235 232 230]\n",
            " [228 228 229 ... 239 238 237]\n",
            " ...\n",
            " [226 226 225 ... 224 232 234]\n",
            " [229 229 229 ... 232 238 240]\n",
            " [230 230 231 ... 237 242 244]]\n",
            "[[242 242 242 ... 247 247 247]\n",
            " [242 242 243 ... 247 247 247]\n",
            " [242 242 243 ... 245 245 245]\n",
            " ...\n",
            " [242 243 243 ... 253 253 253]\n",
            " [242 243 243 ... 253 253 253]\n",
            " [242 243 243 ... 253 253 253]]\n",
            "[[241 241 241 ... 237 238 239]\n",
            " [241 241 241 ... 236 237 238]\n",
            " [241 241 241 ... 235 236 236]\n",
            " ...\n",
            " [232 232 230 ... 249 249 249]\n",
            " [235 235 233 ... 250 250 251]\n",
            " [236 236 234 ... 251 251 251]]\n",
            "[[188 189 190 ... 188 188 188]\n",
            " [188 189 190 ... 189 189 189]\n",
            " [187 187 188 ... 186 186 186]\n",
            " ...\n",
            " [196 196 195 ... 207 205 204]\n",
            " [196 196 196 ... 207 206 205]\n",
            " [197 196 196 ... 207 206 205]]\n",
            "[[186 187 188 ... 186 188 189]\n",
            " [187 188 188 ... 188 189 190]\n",
            " [188 189 190 ... 190 192 193]\n",
            " ...\n",
            " [110 111 113 ... 142 127 121]\n",
            " [ 94  95  99 ... 171 164 163]\n",
            " [ 95  96 101 ... 184 181 183]]\n",
            "[[189 189 190 ... 191 191 190]\n",
            " [189 189 191 ... 191 191 191]\n",
            " [189 189 191 ... 191 191 191]\n",
            " ...\n",
            " [193 192 191 ... 209 210 210]\n",
            " [195 195 193 ... 210 211 212]\n",
            " [196 195 194 ... 211 212 212]]\n",
            "[[125 125 127 ... 121 104  95]\n",
            " [129 130 132 ... 129 111 101]\n",
            " [138 140 146 ... 148 130 119]\n",
            " ...\n",
            " [122 121 115 ... 157 155 153]\n",
            " [121 120 117 ... 191 189 188]\n",
            " [127 127 125 ... 202 201 201]]\n",
            "[[186 186 186 ... 184 183 183]\n",
            " [186 186 185 ... 184 184 183]\n",
            " [186 185 185 ... 184 183 182]\n",
            " ...\n",
            " [195 196 197 ... 206 206 206]\n",
            " [195 196 196 ... 207 207 207]\n",
            " [195 196 196 ... 208 208 208]]\n",
            "[[161 161 162 ... 154 154 153]\n",
            " [156 156 157 ... 161 160 160]\n",
            " [144 144 145 ... 174 173 172]\n",
            " ...\n",
            " [189 191 194 ... 208 208 208]\n",
            " [189 191 195 ... 207 207 208]\n",
            " [188 190 195 ... 207 208 208]]\n",
            "Processing Complete\n"
          ]
        }
      ],
      "source": [
        "#current_directory = os.getcwd()\n",
        "#current_directory = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis'\n",
        "current_directory = r'C:\\Users\\dezos\\OneDrive\\Documents\\FibreAnalysis\\fibreanalysis'\n",
        "print('Current Directory', current_directory)\n",
        "print('Processing Images')\n",
        "\n",
        "# for stageDirectory in [\"Real\"]:\n",
        "# print(\"Processing Stage: \" , stageDirectory)\n",
        "InRawImages = os.path.join(current_directory, 'Data', 'Real', 'Raw',  '')\n",
        "\n",
        "OutPreparedImages = os.path.join(current_directory, 'Data', 'Real', 'Prepared', '')\n",
        "\n",
        "\n",
        "processSynthImages(InRawImages, OutPreparedImages)\n",
        "\n",
        "print('Processing Complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otNiXnvdDmbm"
      },
      "source": [
        "### Create required directory structure for YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNazvCaWDmbo"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/train\n",
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/val\n",
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/train\n",
        "# !mkdir -p  /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPBPeNBtDmbo"
      },
      "outputs": [],
      "source": [
        "# # Move files across for YOLO\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Train/labels/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/train\n",
        "\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Val/labels/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/labels/val\n",
        "\n",
        "\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Train/images/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/train\n",
        "\n",
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/Val/images/* /content/drive/MyDrive/Colab\\ Notebooks/FibreAnalysis/Data/Prepared/YOLO/images/val"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
