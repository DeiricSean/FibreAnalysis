{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn , MaskRCNN_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "current_directory = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize=10\n",
    "imageSize=[600,600]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')   # train on the GPU or on the CPU, if a GPU is not available\n",
    "\n",
    "trainMaskDirectory1 = os.path.join(current_directory, 'Prepared', 'Train', 'masks')\n",
    "maskDir1 = list(sorted(os.listdir(trainMaskDirectory1)))\n",
    "\n",
    "trainImageDirectory = os.path.join(current_directory, 'Prepared', 'Train', 'images')\n",
    "\n",
    "trainDir = list(sorted(os.listdir(trainImageDirectory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    batch_Imgs=[]\n",
    "    batch_Data=[]# load images and masks\n",
    "    for i in range(batchSize):\n",
    "        idx=random.randint(0,len(trainDir)-1)\n",
    "        #img = cv2.imread(os.path.join(imgs[idx], \"Image.jpg\"))\n",
    "                \n",
    "        img = cv2.imread(os.path.join(trainImageDirectory, trainDir[idx]))\n",
    "        img = cv2.resize(img, imageSize, cv2.INTER_LINEAR)\n",
    "        \n",
    "        \n",
    "        fullMask = (cv2.imread(os.path.join(trainMaskDirectory1, maskDir1[idx]), 0) > 0).astype(np.uint8)  # Read vesse instance mask\n",
    "        fullMask=cv2.resize(fullMask,imageSize,cv2.INTER_NEAREST)\n",
    "        \n",
    "        #########################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "             # Get the contours of the image - to find the grid polygons\n",
    "        contours, _ = cv2.findContours(fullMask, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        num_objs = len(contours)\n",
    "        # Create an empty numpy array to store the masks\n",
    "        masks=[]\n",
    "        # Iterate over each contour and update the masks array\n",
    "        for i, contour in enumerate(contours):\n",
    "                # Check if the contour area is greater than 0\n",
    "            if cv2.contourArea(contour) >  0:\n",
    "                # Create a new binary mask for the current contour\n",
    "                contour_mask = np.zeros_like(fullMask, dtype=np.uint8)\n",
    "                # Draw the contour on the binary mask\n",
    "                cv2.drawContours(contour_mask, [contour], 0, (255), thickness=cv2.FILLED)\n",
    "                # Append the contour mask to the masks list\n",
    "                masks.append(contour_mask)\n",
    "\n",
    "        # Convert the masks list to a NumPy array\n",
    "        masks = np.array(masks)\n",
    "            \n",
    "        num_objs = len(masks)\n",
    "        if num_objs==0: return loadData() # if image have no objects just load another image\n",
    "        boxes = torch.zeros([num_objs,4], dtype=torch.float32)\n",
    "        for i in range(num_objs):\n",
    "            x,y,w,h = cv2.boundingRect(masks[i])\n",
    "            boxes[i] = torch.tensor([x, y, x+w, y+h])\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        img = torch.as_tensor(img, dtype=torch.float32)\n",
    "        data = {}\n",
    "        data[\"boxes\"] =  boxes\n",
    "        data[\"labels\"] =  torch.ones((num_objs,), dtype=torch.int64)   # there is only one class\n",
    "        data[\"masks\"] = masks\n",
    "        batch_Imgs.append(img)\n",
    "        batch_Data.append(data)  # load images and masks\n",
    "    batch_Imgs = torch.stack([torch.as_tensor(d) for d in batch_Imgs], 0)\n",
    "    batch_Imgs = batch_Imgs.swapaxes(1, 3).swapaxes(2, 3)\n",
    "    return batch_Imgs, batch_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features  # get number of input features for the classifier\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes=2)  # replace the pre-trained head with a new one\n",
    "model.to(device)# move model to the right devic\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "model.train()\n",
    "\n",
    "for i in range(10001):\n",
    "            images, targets = loadData()\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            print(i,'loss:', losses.item())\n",
    "            if i%500==0:\n",
    "                torch.save(model.state_dict(), str(i)+\".torch\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
