{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training of Detectron2 Model. Based on Detectron2 Tutorial at:\n",
        "# https://detectron2.readthedocs.io/en/latest/tutorials/getting_started.html\n",
        "# https://detectron2.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Installation of detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsePPpwZSmqt",
        "outputId": "673f7553-7ae5-4405-ed7e-fd7157fd0a59"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check Versions and import required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d288Z2mF5dC",
        "outputId": "8db4b44b-5e28-4b3f-81a3-2e5e9a4affed"
      },
      "outputs": [],
      "source": [
        "# Check versions of detectron and torch\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# Some basic setup: Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "### Link Colab to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko7PI6Aiz4sP",
        "outputId": "c3622a55-a5ce-42fa-d27d-ba99cfad8244"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "current_directory = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E76gl4Cu2Ksb"
      },
      "outputs": [],
      "source": [
        "# Optional Step to deregister dataset if it has already been registered \n",
        "# ( if modifying dataset while developing, can be run without any impact if dataset not registered )\n",
        "DatasetCatalog.remove('fibre_Train')\n",
        "DatasetCatalog.remove('fibre_Val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to load fibre images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrJyQktqhfi8"
      },
      "outputs": [],
      "source": [
        "def get_fibre_dicts(img_dir, mask_dir):\n",
        "    img_files = os.listdir(img_dir) # Get list of files in the directory \n",
        "    dataset_dicts = []\n",
        "\n",
        "    for idx, img_file in enumerate(img_files):\n",
        "        record = {}\n",
        "\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "        mask_path = os.path.join(mask_dir, f\"mask{img_file[5:]}\")  # Change filename from image_ to mask _ to retrieve mask\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        record[\"file_name\"] = img_path\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        mask = cv2.imread(mask_path, 0)  # Load the mask image as grayscale\n",
        "\n",
        "        # Get contours from mask file to calculate individual masks and bounding boxes \n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "        objs = []\n",
        "        for contour in contours:\n",
        "            polygon = contour.squeeze().tolist()\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            if len(polygon) >= 6:  # Ensure at least 3 (x, y) coordinate pairs for a valid polygon - otherwise detectron will kick out error\n",
        "                obj = {\n",
        "                    \"bbox\": cv2.boundingRect(contour),\n",
        "                    \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                    \"segmentation\": [polygon],\n",
        "                    \"category_id\": 0,\n",
        "                }\n",
        "                objs.append(obj)\n",
        "\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "\n",
        "    return dataset_dicts\n",
        "\n",
        "# Base directory for the Training files \n",
        "startDirectory = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data/Prepared'\n",
        "\n",
        "for d in [\"Train\", \"Val\"]:\n",
        "    DatasetCatalog.register(\"fibre_\" + d, lambda d=d: get_fibre_dicts(startDirectory + '/' + d + '/images', startDirectory + '/' + d + '/masks'))\n",
        "    MetadataCatalog.get(\"fibre_\" + d).set(thing_classes=[\"fibre\"])\n",
        "fibre_metadata = MetadataCatalog.get(\"fibre_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check that Dataload will work properly, pick an image and show masks and bounding boxes on it "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "kAzlli0G2SMq",
        "outputId": "5d724a22-56ed-460b-915b-297914ebb162"
      },
      "outputs": [],
      "source": [
        "# Display examples with bounding box and masks\n",
        "\n",
        "fibre_images = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data/Prepared/Train/images'\n",
        "fibre_masks = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data/Prepared/Train/masks'\n",
        "\n",
        "dataset_fibre_dicts = get_fibre_dicts(fibre_images, fibre_masks)\n",
        "for d in random.sample(dataset_fibre_dicts, 1):\n",
        "    print(d)  # Print File name \n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=fibre_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "### Train = Fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the fibre dataset. Plot the training on a tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7unkuuiqLdqd",
        "outputId": "5bb06fac-5ea3-4e5d-e3bb-2661c88a187e"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "# cfg.OUTPUT_DIR = \"./output\"    \n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/\" \n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"fibre_Train\",)\n",
        "cfg.DATASETS.TEST = (\"fibre_Val\")\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 10001    # Number of training Iterations \n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". Region of interest head\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (fibre). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on the fibre validation dataset. First, let's create a predictor using the model we just trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya5nEuMELeq8",
        "outputId": "b5774a0c-e108-4e12-8567-3cfe4b32bc0a"
      },
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Format of predictions such as masks and shape masks etc. can be found at \n",
        "# https://detectron2.readthedocs.io/en/latest/tutorials/models.html#model-output-format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U5LhISJqWXgM",
        "outputId": "0adf138d-f84a-4cb8-d98a-140b2b91dd83"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_fibre_dicts(startDirectory + '/Val/images', startDirectory + '/Val/masks')\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    print(d)\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=fibre_metadata,\n",
        "                   scale=0.5,\n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kblA1IyFvWbT"
      },
      "source": [
        "Evaluate the performance using AP metric implemented in COCO API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "h9tECBQCvMv3",
        "outputId": "18752ee4-3a89-4485-e8b5-470ca736483f"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "#evaluator = COCOEvaluator(\"fibre_Val\", output_dir=\"./output\")\n",
        "evaluator = COCOEvaluator(\"fibre_Val\", output_dir=cfg.OUTPUT_DIR)\n",
        "\n",
        "val_loader = build_detection_test_loader(cfg, \"fibre_Val\")\n",
        "\n",
        "# Create a predictor using the trained model\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "print(inference_on_dataset(predictor, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU1e-f7CqsBQ",
        "outputId": "cb8968b9-232a-4e98-ec5f-c3159cbc88b7"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.test(cfg, trainer.model)\n",
        "\n",
        "print(eval_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
