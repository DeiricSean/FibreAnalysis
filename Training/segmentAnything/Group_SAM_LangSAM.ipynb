{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "current_directory = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install opencv-python matplotlib\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "        \n",
    "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U git+https://github.com/luca-medeiros/lang-segment-anything.gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from lang_sam import LangSAM\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_mask_image(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    return img        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(r'C:\\Users\\dezos\\Documents\\Fibres\\FibreAnalysis\\Data\\Prepared\\Train\\images\\image_2023-07-14_21-27-23-748533_1.png')\n",
    "#image = cv2.imread(r'C:\\Users\\dezos\\Documents\\Fibres\\FibreAnalysis\\Data\\Prepared\\Train\\images\\image-682596207.jpg')\n",
    "image = '/content/drive/MyDrive/Colab Notebooks/FibreAnalysis/Data/Prepared/Train/images/image_2023-07-14_21-27-23-748533_1.jpg'\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)\n",
    "mask_image = prep_mask_image(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LangSAM()\n",
    "\n",
    "text_prompt = \"line\"\n",
    "masks, boxes, phrases, logits = model.predict(mask_image, text_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the final mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(mask_np, filename):\n",
    "    mask_image = Image.fromarray((mask_np * 255).astype(np.uint8))\n",
    "    mask_image.save(filename)\n",
    "\n",
    "def display_image_with_masks(image, masks):\n",
    "    num_masks = len(masks)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_masks + 1, figsize=(15, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i, mask_np in enumerate(masks):\n",
    "        axes[i+1].imshow(mask_np, cmap='gray')\n",
    "        axes[i+1].set_title(f\"Mask {i+1}\")\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_image_with_boxes(image, boxes, logits):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(\"Image with Bounding Boxes\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    for box, logit in zip(boxes, logits):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        confidence_score = round(logit.item(), 2)  # Convert logit to a scalar before rounding\n",
    "        box_width = x_max - x_min\n",
    "        box_height = y_max - y_min\n",
    "\n",
    "        # Draw bounding box\n",
    "        rect = plt.Rectangle((x_min, y_min), box_width, box_height, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add confidence score as text\n",
    "        ax.text(x_min, y_min, f\"Confidence: {confidence_score}\", fontsize=8, color='red', verticalalignment='top')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def print_bounding_boxes(boxes):\n",
    "    print(\"Bounding Boxes:\")\n",
    "    for i, box in enumerate(boxes):\n",
    "        print(f\"Box {i+1}: {box}\")\n",
    "\n",
    "def print_detected_phrases(phrases):\n",
    "    print(\"\\nDetected Phrases:\")\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        print(f\"Phrase {i+1}: {phrase}\")\n",
    "\n",
    "def print_logits(logits):\n",
    "    print(\"\\nConfidence:\")\n",
    "    for i, logit in enumerate(logits):\n",
    "        print(f\"Logit {i+1}: {logit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(masks) == 0:\n",
    "    print(f\"No objects of the '{text_prompt}' prompt detected in the image.\")\n",
    "else:\n",
    "    # Convert masks to numpy arrays\n",
    "    masks_np = [mask.squeeze().cpu().numpy() for mask in masks]\n",
    "\n",
    "    # Display the original image and masks side by side\n",
    "    display_image_with_masks(image, masks_np)\n",
    "\n",
    "    # Display the image with bounding boxes and confidence scores\n",
    "    display_image_with_boxes(image, boxes, logits)\n",
    "\n",
    "    # Save the masks\n",
    "    for i, mask_np in enumerate(masks_np):\n",
    "        mask_path = f\"image_mask_{i+1}.png\"\n",
    "        save_mask(mask_np, mask_path)\n",
    "\n",
    "    # Print the bounding boxes, phrases, and logits\n",
    "    print_bounding_boxes(boxes)\n",
    "    print_detected_phrases(phrases)\n",
    "    print_logits(logits)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
